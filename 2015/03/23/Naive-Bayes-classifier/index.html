
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>朴素贝叶斯分类器 | JNing+</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="JNing">
    

    
    <meta name="description" content="最近在看一本叫做机器学习实战的书，感觉写的不错，因为它里面不仅仅讲一些算法的原理，而且最关键的是用python代码实现了其中的应用场景。这里就是一些读书笔记，这次记录的是基于概率论的分类方法：朴素贝叶斯。">
<meta property="og:type" content="article">
<meta property="og:title" content="朴素贝叶斯分类器">
<meta property="og:url" content="https://ningban.github.io/2015/03/23/Naive-Bayes-classifier/index.html">
<meta property="og:site_name" content="JNing+">
<meta property="og:description" content="最近在看一本叫做机器学习实战的书，感觉写的不错，因为它里面不仅仅讲一些算法的原理，而且最关键的是用python代码实现了其中的应用场景。这里就是一些读书笔记，这次记录的是基于概率论的分类方法：朴素贝叶斯。">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="朴素贝叶斯分类器">
<meta name="twitter:description" content="最近在看一本叫做机器学习实战的书，感觉写的不错，因为它里面不仅仅讲一些算法的原理，而且最关键的是用python代码实现了其中的应用场景。这里就是一些读书笔记，这次记录的是基于概率论的分类方法：朴素贝叶斯。">

    
    <link rel="alternative" href="/atom.xml" title="JNing+" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/logo.png">
    <link rel="apple-touch-icon-precomposed" href="/img/logo.png">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="JNing+" title="JNing+"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="JNing+">JNing+</a></h1>
				<h2 class="blog-motto">Stay hungry, Stay foolish...</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:ningban.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/03/23/Naive-Bayes-classifier/" title="朴素贝叶斯分类器" itemprop="url">朴素贝叶斯分类器</a>
  </h1>
  <p class="article-author">By
       
		<a href="https://ningban.github.io/about" title="JNing" target="_blank" itemprop="author">JNing</a>
		
  <p class="article-time">
    <time datetime="2015-03-23T12:26:56.000Z" itemprop="datePublished"> 发表于 2015-03-23</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#朴素贝叶斯引论"><span class="toc-number">1.</span> <span class="toc-text">朴素贝叶斯引论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用条件概率来分类"><span class="toc-number">2.</span> <span class="toc-text">使用条件概率来分类</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用朴素贝叶斯进行文档分类"><span class="toc-number">3.</span> <span class="toc-text">使用朴素贝叶斯进行文档分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯的一般过程"><span class="toc-number">3.1.</span> <span class="toc-text">朴素贝叶斯的一般过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#准备数据：从文本中构建词向量"><span class="toc-number">3.2.</span> <span class="toc-text">准备数据：从文本中构建词向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练算法：从词向量计算概率"><span class="toc-number">3.3.</span> <span class="toc-text">训练算法：从词向量计算概率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#测试算法：根据现实情况修改分类器"><span class="toc-number">3.4.</span> <span class="toc-text">测试算法：根据现实情况修改分类器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#文档词袋模型"><span class="toc-number">3.5.</span> <span class="toc-text">文档词袋模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#python代码"><span class="toc-number">3.6.</span> <span class="toc-text">python代码</span></a></li></ol></li></ol>
		
		</div>
		
		<h1 id="朴素贝叶斯引论">朴素贝叶斯引论</h1><p>　　对于分类而言，使用概率有时要比使用硬规则更为有效。贝叶斯概率及贝叶斯准则提供了一种利用已知值来估计未知概率的有效方法。<br>　　可以通过特征之间的条件独立性假设，降低对数据量的需求。独立性假设是指一个词的出现概率并不依赖于文档中的其他词。当然我们也知道这个假设过于简单。这就是<code>之所以称为朴素贝叶斯的原因</code>。尽管条件独立性假设不正确，但是朴素贝叶斯仍然是一种有效的分类器。</p>
<h1 id="使用条件概率来分类">使用条件概率来分类</h1><p>　　贝叶斯决策理论要求计算两个概率$p_1(x, y)$和$p_2(x, y)$：<br>　　1. 如果$p_1(x, y) &gt; p_2(x, y)$，那么属于类别1；<br>　　2. 如果$p_2(x, y) &gt; p_1(x, y)$，那么属于类别2。<br>　　但这两个准则并不是贝叶斯决策理论的所有内容。使用$p_1$和$p_2$只是为了尽可能简化描述，而真正需要计算和比较的是$p(c_1|x, y)$和$p(c_2| x, y)$。这些符号代表的具体意义是：给定某个由(x, y)表示的数据点，那么该数据点来自类别$c_1$的概率是多少？数据点来自类别$c_2$的概率又是多少？注意这些概率与概率$p(x, y|c_1)$并不一样，不过可以使用贝叶斯准则来交换概率条件与结果。具体地，应用贝叶斯准则得到：<br>$$p(c_i|x, y) = \frac{p(x, y|c_i)p(c_i)}{p(x, y)}\qquad$$<br>　　使用这些定义，可以定义贝叶斯分类准则为：<br>　　1. 如果$p(c_1|x, y) &gt; p(c_2|x, y)$，那么属于类别$c_1$；<br>　　2. 如果$p(c_1|x, y) &lt; p(c_2|x, y)$，那么属于类别$c_2$。<br>　　使用贝叶斯准则，可以通过已知的三个概率值来计算未知的概率值。后面就会给出利用贝叶斯准则来计算概率并对数据进行分类的代码。</p>
<h1 id="使用朴素贝叶斯进行文档分类">使用朴素贝叶斯进行文档分类</h1><p>　　机器学习的一个重要应用就是文档的自动分类。在文档分类中，整个文档（如一封电子邮件）是实例，而电子邮件中的某些元素则构成特征。虽然电子邮件是一种会不断增加的文本，但我们同样也可以对新闻报道/用户留言/政府公文等其他任意类型的文本进行分类。我们可以观察文档中出现的词，并把没每个词的出现或者不出现作为一个特征，这样得到的特征数目就会跟词汇表中的词目一样多。朴素贝叶斯是贝叶斯分类器的一个扩展，是用于文档分类的常用算法。</p>
<h2 id="朴素贝叶斯的一般过程">朴素贝叶斯的一般过程</h2><p>　　1. 收集数据：可以使用任何方法；<br>　　2. 准备数据：需要数值型或者布尔型数据；<br>　　3. 分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好；<br>　　4. 训练算法：计算不同的独立特征的条件概率；<br>　　5. 测试算法：计算错误率；<br>　　6. 使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。</p>
<h2 id="准备数据：从文本中构建词向量">准备数据：从文本中构建词向量</h2><p>　　我们将把文本看成单词向量或者词条向量，也就是说将句子转换为向量。考虑出现在所有文档中的所有单词，再决定将哪些词纳入词汇表或者说所要的词汇集合，然后必须要将每一篇文档转换为词汇表上的向量。</p>
<h2 id="训练算法：从词向量计算概率">训练算法：从词向量计算概率</h2><p>　　上面介绍了如何将一组单词转换为一组数字，接下来看看如何使用这些数字计算概率。现在已经知道一个词是否出现在一篇文档中，也知道该文档所属的类别。我们重写贝叶斯规则，将之前的x，y替换为w。w表示这是一个向量，即它由多个数值组成。<br>$$p(c_i|w) = \frac{p(w|c_i)p(c_i)}{p(w)}$$<br>　　我们将使用上述公式，对每个类计算该值，然后比较这两个概率值的大小。如何计算呢？首先可以通过类别i（侮辱性留言或非侮辱性留言）中文档数除以总的文档数来计算概率$p(c_i)$。接下来计算$p(w|c_i)$，这里就要用到朴素贝叶斯假设。如果将w展开为一个个独立特征，那么就可以将上述概率写作$p(w_0, w_1, w_2, …, w_n|c_i)$。这里假设所有词都相互独立，该假设也称作条件独立性假设，它意味着可以使用$p(w_0|c_i)p(w_1|c_i)p(w_2|c_i)…p(w_n|c_i)$来计算上述概率，这就极大地简化了计算过程。</p>
<h2 id="测试算法：根据现实情况修改分类器">测试算法：根据现实情况修改分类器</h2><p>　　第一个问题：利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算$p(w_0|c_1)p(w_1|c_1)p(w_2|c_1)$…。如果其中一个概率值为0，那么最后的乘积也为0。为了降低这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2。<br>　　第二个问题：下溢出，这是由于太多很小的数相乘造成的。当计算乘积$p(w_0|c_1)p(w_1|c_1)p(w_2|c_1)$…时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。一种解决办法是对乘积取自然对数。在代数中有ln(a*b) = ln(a) + ln(b)，于是通过求对数可以避免下溢出或者浮点数导致的错误。</p>
<h2 id="文档词袋模型">文档词袋模型</h2><p>　　到目前未知，我们将每个词的出现与否作为一个特征，这可以被描述为<code>词集模型</code>(set-of-words model)。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为<code>词袋模型</code>(bags-of-words model)。在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。为了适应词袋模型，每当遇到一个单词时，它会增加词向量中的对应值，而不只是将对应的数值设为1。<br>　　另外，词汇表中的一小部分单词却占据了所有文本用词的大部分。产生这种现象的原因是因为语言中大部分都是冗余和结构辅助性内容。一个常用的方法是<code>移除高频词</code>，另一个常用的方法是不仅移除高频词，同时从某个预定词表中移除结构上的辅助词。该词表称为<code>停用词表</code>（stop word list），当然也可以花大量时间对切分器进行优化。</p>
<h2 id="python代码">python代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#-*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="comment">#FileName:bayes.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：初始化数据集，即文档矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">()</span>:</span></span><br><span class="line">  postingList = [[<span class="string">'my'</span>, <span class="string">'dog'</span>, <span class="string">'has'</span>, <span class="string">'flea'</span>, <span class="string">'problems'</span>, <span class="string">'help'</span>, <span class="string">'please'</span> ],</span><br><span class="line">  		[<span class="string">'maybe'</span>, <span class="string">'not'</span>, <span class="string">'take'</span>, <span class="string">'him'</span>,<span class="string">'to'</span>, <span class="string">'dog'</span>,<span class="string">'park'</span>, <span class="string">'stupid'</span>],</span><br><span class="line">  		[<span class="string">'my'</span>, <span class="string">'dalmation'</span>, <span class="string">'is'</span>, <span class="string">'so'</span>, <span class="string">'cute'</span>, <span class="string">'I'</span>, <span class="string">'love'</span>, <span class="string">'him'</span>],</span><br><span class="line">  		[<span class="string">'stop'</span>, <span class="string">'posting'</span>, <span class="string">'stupid'</span>, <span class="string">'worthless'</span>, <span class="string">'garbage'</span>],</span><br><span class="line">  		[<span class="string">'mr'</span>, <span class="string">'licks'</span>, <span class="string">'ate'</span>, <span class="string">'my'</span>, <span class="string">'steak'</span>, <span class="string">'how'</span>, <span class="string">'to'</span>, <span class="string">'stop'</span>, <span class="string">'him'</span>],</span><br><span class="line">  		[<span class="string">'quit'</span>, <span class="string">'buying'</span>, <span class="string">'worthless'</span>, <span class="string">'dog'</span>, <span class="string">'food'</span>, <span class="string">'stupid'</span>]]</span><br><span class="line">  classVec = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>] <span class="comment">#1代表侮辱性文字,0代表正常言论</span></span><br><span class="line">  <span class="keyword">return</span> postingList, classVec</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：初始化词表</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	dataSet ==&gt; 数据集，即文档矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createVocabList</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">  vocabSet = set([])</span><br><span class="line">  <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">  	vocabSet = vocabSet | set(document) <span class="comment">#取并集</span></span><br><span class="line">  <span class="keyword">return</span> list(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：给定一篇文档，该文档就会被转换为词向量，</span></span><br><span class="line"><span class="comment">#	        0代表不在输入集中，1代表在输入集中</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	vocabList ==&gt; 词表</span></span><br><span class="line"><span class="comment">#	inputSet   ==&gt; 输入集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setOfWords2Vec</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">  returnVec = [<span class="number">0</span>]*len(vocabList)  <span class="comment">#初始化一个其中所有元素都为0的向量</span></span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">  	<span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">  		returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">  	<span class="keyword">else</span>:</span><br><span class="line">  		<span class="keyword">print</span> <span class="string">'the word: =%s is not in my vocabulary!'</span> %word</span><br><span class="line">  <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：朴素贝叶斯分类器训练函数</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	trainMatrix       ==&gt; 训练矩阵（由0,1词向量组成）</span></span><br><span class="line"><span class="comment">#	trainCategory  ==&gt; 训练矩阵的分类，0为正常言论，1为侮辱性文字</span></span><br><span class="line"><span class="comment"># 根据现实情况修改分类器：</span></span><br><span class="line"><span class="comment">#1. 利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，</span></span><br><span class="line"><span class="comment">#	即计算p(w0|c1)p(w1|c1)p(w2|c1)...。如果其中一个概率值为0，那么最后的乘积也为0。</span></span><br><span class="line"><span class="comment">#	为了降低这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2。</span></span><br><span class="line"><span class="comment">#2.另一个问题是下溢出，这是由于太多很小的数相乘造成的。当计算乘积p(w0|c1)p(w1|c1)p(w2|c1)...</span></span><br><span class="line"><span class="comment">#	时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。一种解决办法是对乘积取自然对数。</span></span><br><span class="line"><span class="comment">#	在代数中有ln(a*b) = ln(a) + ln(b)，于是通过求对数可以避免下溢出或者浮点数导致的错误。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix, trainCategory)</span>:</span></span><br><span class="line">  numTrainDocs = len(trainMatrix) <span class="comment">#文档数</span></span><br><span class="line">  numWords = len(trainMatrix[<span class="number">0</span>]) <span class="comment">#文档中单词的数目</span></span><br><span class="line">  pAbusive    = sum(trainCategory)/float(numTrainDocs) <span class="comment">#侮辱性文档出现的概率</span></span><br><span class="line">  p0Num = ones(numWords) <span class="comment">#初始化零向量，用于正常文档中的单词</span></span><br><span class="line">  p1Num = ones(numWords) <span class="comment">#初始化零向量，用于侮辱性文档中的单词</span></span><br><span class="line">  p0Denom = <span class="number">2.0</span></span><br><span class="line">  p1Denom = <span class="number">2.0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):</span><br><span class="line">  	<span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">  		p1Num += trainMatrix[i]</span><br><span class="line">  		p1Denom += sum(trainMatrix[i])</span><br><span class="line">  	<span class="keyword">else</span>:</span><br><span class="line">  		p0Num += trainMatrix[i]</span><br><span class="line">  		p0Denom += sum(trainMatrix[i])</span><br><span class="line">  p1Vect = log(p1Num/p1Denom)</span><br><span class="line">  p0Vect = log(p0Num/p0Denom)</span><br><span class="line">  <span class="keyword">return</span> p0Vect, p1Vect, pAbusive</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：朴素贝叶斯分类函数</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	vec2Classify ==&gt; 要分类的向量</span></span><br><span class="line"><span class="comment">#	p0Vec            ==&gt; trainNB0函数返回的p0Vect</span></span><br><span class="line"><span class="comment">#	p1Vec 	         ==&gt; trainNB0函数返回的p1Vect</span></span><br><span class="line"><span class="comment">#	pClass1         ==&gt; trainNB0函数返回的pAbusive</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">  p1 = sum(vec2Classify * p1Vec) + log(pClass1) <span class="comment">#因为取了对数，所以概率相乘变为了相加</span></span><br><span class="line">  p0 = sum(vec2Classify * p0Vec) + log(<span class="number">1.0</span> - pClass1) </span><br><span class="line">  <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">  	<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">  	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：测试函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testingNB</span><span class="params">()</span>:</span></span><br><span class="line">  list0Posts, listClasses = loadDataSet()</span><br><span class="line">  myVocabList = createVocabList(list0Posts)</span><br><span class="line">  trainMat = [] <span class="comment">#把文档矩阵转换为词向量矩阵</span></span><br><span class="line">  <span class="keyword">for</span> postinDoc <span class="keyword">in</span> list0Posts:</span><br><span class="line">  	trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">  p0V,p1V,pAb = trainNB0(trainMat, listClasses) <span class="comment">#训练函数</span></span><br><span class="line">  testEntry = [<span class="string">'love'</span>, <span class="string">'my'</span>, <span class="string">'dalmation'</span>]</span><br><span class="line">  thisDoc = setOfWords2Vec(myVocabList, testEntry)  <span class="comment">#转化为词向量</span></span><br><span class="line">  <span class="keyword">print</span> testEntry,<span class="string">'classified as: '</span>, classifyNB(thisDoc, p0V, p1V, pAb) <span class="comment">#分类函数</span></span><br><span class="line">  testEntry = [<span class="string">'stupid'</span>, <span class="string">'garbage'</span>]</span><br><span class="line">  thisDoc = setOfWords2Vec(myVocabList, testEntry)</span><br><span class="line">  <span class="keyword">print</span> testEntry,<span class="string">'classified as: '</span>, classifyNB(thisDoc, p0V, p1V, pAb)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：朴素贝叶斯次贷模型</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	vocabList ==&gt; 词表</span></span><br><span class="line"><span class="comment">#	inputSet   ==&gt; 输入集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bagOfWords2VecMN</span><span class="params">(vocabList, inputSet)</span>:</span></span><br><span class="line">  returnVec = [<span class="number">0</span>]*len(vocabList)</span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">  	<span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">  		returnVec[vocabList.index(word)] += <span class="number">1</span></span><br><span class="line">  <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：文本解析</span></span><br><span class="line"><span class="comment">#param：</span></span><br><span class="line"><span class="comment">#	bigString ==&gt; 文本</span></span><br><span class="line"><span class="comment">#关于正则表达式：</span></span><br><span class="line"><span class="comment">#	\d  ==&gt; [0-9]</span></span><br><span class="line"><span class="comment">#	\D ==&gt; 非 \d</span></span><br><span class="line"><span class="comment">#	\s  ==&gt; 表示空字符</span></span><br><span class="line"><span class="comment">#	\S  ==&gt; 非空字符</span></span><br><span class="line"><span class="comment">#	\w ==&gt; [a-zA-Z0-9_]</span></span><br><span class="line"><span class="comment">#	\W ==&gt; 非 \w</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textParse</span><span class="params">(bigString)</span>:</span></span><br><span class="line">  <span class="keyword">import</span> re</span><br><span class="line">  listOfTokens = re.split(<span class="string">r'\W*'</span>, bigString)</span><br><span class="line">  <span class="keyword">return</span> [tok.lower() <span class="keyword">for</span> tok <span class="keyword">in</span> listOfTokens <span class="keyword">if</span> len(tok)&gt;<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Function：垃圾邮件测试</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spamTest</span><span class="params">()</span>:</span></span><br><span class="line">  docList = [] <span class="comment">#文档列表</span></span><br><span class="line">  classList = [] <span class="comment">#类别列表</span></span><br><span class="line">  <span class="comment">#垃圾邮件文本和普通邮件文本都是25个</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">26</span>):</span><br><span class="line">  	wordList = textParse(open(<span class="string">'email/spam/%d.txt'</span> %i).read())</span><br><span class="line">  	docList.append(wordList)</span><br><span class="line">  	classList.append(<span class="number">1</span>)</span><br><span class="line">  	wordList = textParse(open(<span class="string">'email/ham/%d.txt'</span> %i).read())</span><br><span class="line">  	docList.append(wordList)</span><br><span class="line">  	classList.append(<span class="number">0</span>)</span><br><span class="line">  vocabList = createVocabList(docList) <span class="comment">#初始化词表</span></span><br><span class="line">  trainingSet = range(<span class="number">50</span>)</span><br><span class="line">  testSet = []</span><br><span class="line">  <span class="comment">#从训练集合中随机拿出10个样本作为测试样本，这样训练集合还剩40个样本</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">  	randIndex = int(random.uniform(<span class="number">0</span>, len(trainingSet)))</span><br><span class="line">  	testSet.append(trainingSet[randIndex])</span><br><span class="line">  	<span class="keyword">del</span>(trainingSet[randIndex])</span><br><span class="line">  trainMat = []</span><br><span class="line">  trainClasses = []</span><br><span class="line">  <span class="comment">#训练集</span></span><br><span class="line">  <span class="keyword">for</span> docIndex <span class="keyword">in</span> trainingSet:</span><br><span class="line">  	trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex]))</span><br><span class="line">  	trainClasses.append(classList[docIndex])</span><br><span class="line">  p0V,p1V,pSpam = trainNB0(trainMat, trainClasses)</span><br><span class="line">  errorCount = <span class="number">0</span></span><br><span class="line">  <span class="comment">#测试集</span></span><br><span class="line">  <span class="keyword">for</span> docIndex <span class="keyword">in</span> testSet:</span><br><span class="line">  	wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])</span><br><span class="line">  	<span class="keyword">if</span> classifyNB(wordVector, p0V, p1V, pSpam) != classList[docIndex]:</span><br><span class="line">  		errorCount += <span class="number">1</span></span><br><span class="line">  		<span class="keyword">print</span> <span class="string">"classification error"</span>,docList[docIndex]</span><br><span class="line">  <span class="keyword">print</span> <span class="string">'the error rate is: '</span>,float(errorCount)/len(testSet)</span><br></pre></td></tr></table></figure>
<p> [参考资料]</p>
<ol>
<li><a href="">机器学习实战</a></li>
<li><a href="http://pan.baidu.com/s/1eQEOOCU" target="_blank" rel="external">本文用到的代码与数据样本</a></li>
</ol>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://ningban.github.io/2015/03/23/Naive-Bayes-classifier/" data-title="朴素贝叶斯分类器 | JNing+" data-tsina="null" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2015/03/20/ID3-algorithm/"  title="决策树算法之ID3算法">
 <strong>下一篇：</strong><br/> 
 <span>决策树算法之ID3算法
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2015/03/23/Naive-Bayes-classifier/" data-title="朴素贝叶斯分类器" data-url="https://ningban.github.io/2015/03/23/Naive-Bayes-classifier/"></div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#朴素贝叶斯引论"><span class="toc-number">1.</span> <span class="toc-text">朴素贝叶斯引论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用条件概率来分类"><span class="toc-number">2.</span> <span class="toc-text">使用条件概率来分类</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用朴素贝叶斯进行文档分类"><span class="toc-number">3.</span> <span class="toc-text">使用朴素贝叶斯进行文档分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯的一般过程"><span class="toc-number">3.1.</span> <span class="toc-text">朴素贝叶斯的一般过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#准备数据：从文本中构建词向量"><span class="toc-number">3.2.</span> <span class="toc-text">准备数据：从文本中构建词向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练算法：从词向量计算概率"><span class="toc-number">3.3.</span> <span class="toc-text">训练算法：从词向量计算概率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#测试算法：根据现实情况修改分类器"><span class="toc-number">3.4.</span> <span class="toc-text">测试算法：根据现实情况修改分类器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#文档词袋模型"><span class="toc-number">3.5.</span> <span class="toc-text">文档词袋模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#python代码"><span class="toc-number">3.6.</span> <span class="toc-text">python代码</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="categorieslist">
	<p class="asidetitle">分类</p>
		<ul>
		
		  
			<li><a href="/categories/Hexo/" title="Hexo">Hexo<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/Life/" title="Life">Life<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/Machine-Learning/" title="Machine Learning">Machine Learning<sup>14</sup></a></li>
		  
		
		  
			<li><a href="/categories/Operating-System/" title="Operating System">Operating System<sup>8</sup></a></li>
		  
		
		  
			<li><a href="/categories/Python/" title="Python">Python<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/分享与发现/" title="分享与发现">分享与发现<sup>2</sup></a></li>
		  
		
		  
			<li><a href="/categories/计算机基础/" title="计算机基础">计算机基础<sup>3</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>14</sup></a></li>
			
		
			
				<li><a href="/tags/OS/" title="OS">OS<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/计算机基础/" title="计算机基础">计算机基础<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Hexo/" title="Hexo">Hexo<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Life/" title="Life">Life<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/分享与发现/" title="分享与发现">分享与发现<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://www.v2ex.com/?r=Jning"" target="_blank" title="v2ex">v2ex</a>
            
          </li>
        
          <li>
            
            	<a href="http://open.163.com" target="_blank" title="公开课">公开课</a>
            
          </li>
        
          <li>
            
            	<a href="http://study.163.com" target="_blank" title="云课堂">云课堂</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.mooc.cn/" target="_blank" title="MOOC">MOOC</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.cnblogs.com/ningvsban" target="_blank" title="JNing">JNing</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, I&#39;m JNing. <br/>
			This is my blog, believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2015 
		
		<a href="https://ningban.github.io/about" target="_blank" title="JNing">JNing</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
    
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#nothing"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>



<script type="text/javascript">
  var duoshuoQuery = {short_name:"ningban## e.g. wuchong   your duoshuo short name."};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
